{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from ipywidgets import interactive, interactive_output, interact_manual\n",
    "\n",
    "import ipywidgets as widgets\n",
    "# import cv2\n",
    "import time\n",
    "import mediapy\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "mpl.rcParams['figure.figsize'] = [16.0, 12.0]\n",
    "\n",
    "# %aimport plot_functions, seqslam_tools\n",
    "# from seqslam_tools import seqSLAM_from_distMat, seqSLAM_from_distMatGPU, seqSLAM_from_distMatGPU_multi, seqSLAM_from_distMatGPU_multi_precomputed\n",
    "# from plot_functions import compare_images_triple, plot_image_on_ax, getPRCurveWrapper, getPRCurveWrapperFromScores, getPAt100R, getPAt100RFromPRVals, getRAtXPFromPRVals\n",
    "\n",
    "import seaborn as sns; sns.set(); sns.set_style(\"whitegrid\"); sns.set_context(\"notebook\")\n",
    "# import seaborn_image as isns; isns.set_context(\"notebook\"); isns.set_image(origin=\"upper\")\n",
    "\n",
    "import tonic\n",
    "import tonic.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc42a1c403447fcbf723cc274375046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bags_2021-08-19-08-25-42_denoised.feather\n",
      "bags_2021-08-19-08-28-43_denoised.feather\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(346, 260)\n",
      "167.191164\n",
      "164.199562\n",
      "(37105401, 4)\n"
     ]
    }
   ],
   "source": [
    "qcr_traverses = [\n",
    "    'bags_2021-08-19-08-25-42_denoised.feather', # S11 side-facing, slow\n",
    "    'bags_2021-08-19-08-28-43_denoised.feather', # S11 side-facing, slow\n",
    "    'bags_2021-08-19-09-45-28_denoised.feather'#, # S11 side-facing, slow\n",
    "]\n",
    "traverses_to_compare = qcr_traverses[0:2] #list of filenames\n",
    "time_windows_overwrite = {  # roughly normalise time windows for traverses where robot was going faster\n",
    "    'bags_2021-08-20-10-19-45': 1e6*0.4,\n",
    "    'bags_2021-10-26-15-56-15': 1e6*0.4,\n",
    "}\n",
    "\n",
    "\n",
    "path_to_qcr_event_files = './Data/' # '/media/tobias/storageSSD/qcr-event-zips/'\n",
    "\n",
    "event_streams = [] #list of len 2 with qry and ref dataframes in each\n",
    "for traverse in tqdm(traverses_to_compare):\n",
    "    print(traverse)\n",
    "    event_streams.append(pd.read_feather(os.path.join(path_to_qcr_event_files, traverse)))\n",
    "\n",
    "print(type(event_streams[0]))\n",
    "\n",
    "im_width, im_height = int(event_streams[0]['x'].max() + 1), int(event_streams[0]['y'].max() + 1)\n",
    "\n",
    "ordering = \"txyp\"\n",
    "\n",
    "x_index = ordering.find(\"x\")\n",
    "y_index = ordering.find(\"y\")\n",
    "t_index = ordering.find(\"t\")\n",
    "p_index = ordering.find(\"p\")\n",
    "\n",
    "sensor_size = (im_width, im_height)\n",
    "print(sensor_size)\n",
    "\n",
    "# Print durations of traverses\n",
    "for event_stream in event_streams:\n",
    "    print((event_stream.iloc[-1]['t'] - event_stream.iloc[0]['t']) / 10e5)\n",
    "\n",
    "event_streams_numpy = [event_stream.to_numpy(np.uint64) for event_stream in event_streams] #converts dataframe to numpy array\n",
    "print(event_streams_numpy[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37105401, 4)\n"
     ]
    }
   ],
   "source": [
    "#event_frames shape for qry and ref - (164, 2, 346, 260) - [:,0,:,:] - pos events - [:,1,:,:] - neg events\n",
    "print(event_streams_numpy[0].shape)\n",
    "# sensor_size = (346, 260,2)\n",
    "# test = tonic.functional.to_frame_numpy(event_streams_numpy[0], sensor_size, ordering, time_window = 1e6)#,ordering,time_window=1e6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "event_frames = [tonic.functional.to_frame_numpy(event_stream_numpy, sensor_size,ordering,\n",
    "                                                time_window=1e6,\n",
    "                                                # overlap=time_windows_overwrite.get(traverse, 1e6) * 9 / 10,\n",
    "                                                ) for traverse, event_stream_numpy in zip(traverses_to_compare, event_streams_numpy)]\n",
    "\n",
    "\n",
    "event_frames_pos = [event_frame[:, 0, :, :] for event_frame in event_frames]\n",
    "event_frames_neg = [event_frame[:, 1, :, :] for event_frame in event_frames]\n",
    "event_frames_total = [event_frame_pos + event_frame_neg for event_frame_pos, event_frame_neg in zip(event_frames_pos, event_frames_neg)]\n",
    "print(event_frames_total[0].shape)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get them synced\n",
    "#get rid of small differences in offsets\n",
    "def get_short_traverse_name(traverse_name):\n",
    "    m=re.search(r'(\\d)[^\\d]*$', traverse_name)\n",
    "    traverse_short = traverse_name[:m.start()+1]\n",
    "    return traverse_short\n",
    "\n",
    "event_frames_total_cropped = []\n",
    "for event_frames, name in zip(event_frames_total, traverses_to_compare):\n",
    "    short_name = get_short_traverse_name(name)\n",
    "    if short_name == 'bags_2021-10-21-10-32-55':\n",
    "        event_frames_total_cropped.append(event_frames[:165])\n",
    "    elif short_name == 'bags_2021-08-19-08-25-42' or short_name == 'bags_2021-08-19-09-45-28':\n",
    "        event_frames_total_cropped.append(event_frames[2:166])\n",
    "    else:\n",
    "        event_frames_total_cropped.append(event_frames)\n",
    "[e.shape for e in event_frames_total_cropped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 15\n",
    "\n",
    "print(np.count_nonzero(event_frames_total_cropped[0][event_frames_total_cropped[0] > 10]))\n",
    "print(np.count_nonzero(event_frames_total_cropped[0][event_frames_total_cropped[0] < 10]) / np.count_nonzero(event_frames_total_cropped[0][event_frames_total_cropped[0] > 10]))\n",
    "\n",
    "event_frames_total_thresh = np.copy(event_frames_total_cropped)\n",
    "event_frames_total_thresh[0][event_frames_total_thresh[0] > thresh] = thresh\n",
    "event_frames_total_thresh[1][event_frames_total_thresh[1] > thresh] = thresh\n",
    "print(event_frames_total_thresh[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.title('Event camera sum of events')\n",
    "\n",
    "for event_frame_total in event_frames_total_thresh:\n",
    "    print(event_frame_total.shape)\n",
    "    plt.plot(np.arange(len(event_frame_total)), event_frame_total.sum(axis=(1,2)))\n",
    "plt.ylim(0, 1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_means = [event_frame_total.mean(axis=0) for event_frame_total in event_frames_total_thresh]\n",
    "plt.figure()\n",
    "plt.title('Event camera mean of events')\n",
    "sns.heatmap(event_means[1].T, robust=True, square=True, cbar=True)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Event camera mean of events')\n",
    "sns.heatmap(event_means[0].T, robust=True, square=True, cbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(event_means[0].shape)\n",
    "print(np.argmax(event_means[0]))\n",
    "print(np.argsort(event_means[0], axis = None)[::-1])\n",
    "print(np.unravel_index(np.argmax(event_means[0]), event_means[0].shape))\n",
    "\n",
    "top_pixels = np.argsort(event_means[0], axis = None)[::-1]\n",
    "# Single pixel\n",
    "plt.figure()\n",
    "plt.title('Event camera number of events for particular pixel')\n",
    "\n",
    "for event_frame_total in event_frames_total_thresh:\n",
    "    plt.plot(np.arange(len(event_frame_total)), event_frame_total[:, 120, 259])\n",
    "    print(event_frame_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(event_frames_total_thresh[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "filter_size=100\n",
    "number_of_pixels=1000\n",
    "correlation_method = 'diff'\n",
    "\n",
    "total_number_pixels = event_frames_total_thresh[0].shape[1]*event_frames_total_thresh[0].shape[2]\n",
    "dmat_cumulative = np.zeros((len(event_frames_total_thresh[0])-filter_size+1,len(event_frames_total_thresh[0])-filter_size+1))\n",
    "\n",
    "arr = np.arange(total_number_pixels)\n",
    "np.random.shuffle(arr) #random selection of pixels\n",
    "# arr = top_pixels\n",
    "\n",
    "# dmat_cumulative = np.zeros((len(ref)-filter_size+1,len(ref)-filter_size+1))\n",
    "\n",
    "for pixel_ind in tqdm(arr[0:number_of_pixels]):\n",
    "\n",
    "    x_pix, y_pix = np.unravel_index(pixel_ind, event_means[0].shape)\n",
    "    ref = event_frames_total_thresh[0][:,x_pix,y_pix]\n",
    "    qry = event_frames_total_thresh[1][:,x_pix,y_pix]\n",
    "\n",
    "    dmat = np.zeros((len(ref)-filter_size+1,len(ref)-filter_size+1))\n",
    "    for filter_ind in np.arange(len(ref)-filter_size+1):\n",
    "        filter = qry[filter_ind:filter_ind+filter_size]\n",
    "        corr = np.correlate(ref, filter)\n",
    "        corr_norm = corr / np.max(corr)\n",
    "\n",
    "        corr_diff = np.zeros(corr.shape)\n",
    "        for idx in np.arange(len(corr_diff)):\n",
    "            corr_diff[idx] = np.sum(np.abs(ref[idx:idx+filter_size] - filter))\n",
    "        corr_diff_norm = corr_diff / np.max(corr_diff)\n",
    "        if correlation_method == \"diff\":\n",
    "            dmat[:,filter_ind] = corr_diff #or corr\n",
    "        else:\n",
    "            dmat[:,filter_ind] = corr #or corr\n",
    "        \n",
    "    dmat_cumulative += dmat\n",
    "dmat_cumulative /= np.max(dmat_cumulative)\n",
    "\n",
    "if correlation_method == \"corr\":\n",
    "    dmat_cumulative = 1-dmat_cumulative\n",
    "\n",
    "sns.heatmap(dmat_cumulative, robust=True, square=True, cbar=True)\n",
    "_ = plt.title('Correlation Distance matrix event camera')\n",
    "\n",
    "np.savez(\"dMats/dMat_test.npz\", dMat=dmat_cumulative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ref_traverse = 0\n",
    "query_traverse = 1\n",
    "print(event_frames_total_thresh[ref_traverse].shape)\n",
    "ref_vec = event_frames_total_thresh[ref_traverse].reshape(event_frames_total_thresh[ref_traverse].shape[0], -1)\n",
    "qry_vec = event_frames_total_thresh[query_traverse].reshape(event_frames_total_thresh[query_traverse].shape[0], -1)\n",
    "dMat = cdist(ref_vec, qry_vec ,'euclidean')\n",
    "dMat /= np.max(dMat)\n",
    "print(ref_vec.shape)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(dMat, robust=True, square=True, cbar=True)\n",
    "_ = plt.title('Distance matrix event camera')\n",
    "\n",
    "np.savez(\"dMats/dMat_test2.npz\", dMat=dMat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_to_draw_from = np.copy(event_means[0])\n",
    "# prob_to_draw_from[np.logical_and(prob_to_draw_from < 0.5, prob_to_draw_from != 0.0)] = 0.01\n",
    "\n",
    "# Set low prob for \"hot pixels\"\n",
    "prob_to_draw_from[prob_to_draw_from > (event_means[0].mean() + 2*event_means[0].std())] = 0.01\n",
    "prob_sum = prob_to_draw_from.sum()\n",
    "prob_to_draw_from = prob_to_draw_from / prob_sum\n",
    "\n",
    "recall_dict = {}\n",
    "used_pixels_dict = {}\n",
    "use_saliency = True\n",
    "\n",
    "seq_length = 15\n",
    "maxLocRad = 4\n",
    "gt_tolerance = maxLocRad\n",
    "precomputed_convWeight = torch.eye(seq_length, device='cpu').unsqueeze(0).unsqueeze(0)\n",
    "precomputed_convWeight_seq1 = torch.eye(1, device='cpu').unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "precomputed_convWeight = torch.eye(seq_length, device='cpu').unsqueeze(0).unsqueeze(0)\n",
    "precomputed_convWeight_seq1 = torch.eye(1, device='cpu').unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "num_trials = 15\n",
    "\n",
    "num_target_pixels_list = [1, 2, 5, 10, 20, 50, 100, 150, 200, 250]\n",
    "# num_target_pixels_list = [8]\n",
    "\n",
    "for num_target_pixels in tqdm(num_target_pixels_list):\n",
    "    if num_target_pixels in recall_dict:\n",
    "        tqdm.write('skip')\n",
    "        continue\n",
    "\n",
    "    recall_dict[num_target_pixels] = []\n",
    "    used_pixels_dict[num_target_pixels] = []\n",
    "\n",
    "    for _ in range(num_trials):\n",
    "        target_pixels = []\n",
    "        while len(target_pixels) < num_target_pixels:\n",
    "            random_idx_flat = np.random.choice(np.arange(0, im_height*im_width), p=prob_to_draw_from.reshape(-1) if use_saliency else None)\n",
    "            random_pixel = np.unravel_index(random_idx_flat, (im_height, im_width))\n",
    "            if len(target_pixels) == 0 or np.all(np.linalg.norm(np.array(target_pixels) - np.array(random_pixel), axis=1) > 3):\n",
    "                target_pixels.append(random_pixel)\n",
    "\n",
    "        # target_pixels_x = np.array([100, 100, 100, 100, 100, 100, 100, 100])\n",
    "        # target_pixels_y = np.array([0,   25,  50,  75, 100, 125, 150, 175])\n",
    "        # target_pixels = np.vstack((target_pixels_x, target_pixels_y)).T\n",
    "\n",
    "        dist_matrices = []\n",
    "        for target_pixel in target_pixels:\n",
    "            count_traverse_ref = torch.from_numpy(event_frames_total_cropped[0][:, target_pixel[1], target_pixel[0]].astype(np.float32)).unsqueeze(0)\n",
    "            count_traverse_qry = torch.from_numpy(event_frames_total_cropped[1][:, target_pixel[1], target_pixel[0]].astype(np.float32)).unsqueeze(0)\n",
    "            dist_matrix_single = torch.abs(count_traverse_ref.unsqueeze(2) - count_traverse_qry.unsqueeze(1)).to('cpu').type(torch.FloatTensor).unsqueeze(0).squeeze(-1)\n",
    "            dist_matrices.append(dist_matrix_single)\n",
    "\n",
    "        dist_matrices_stacked = torch.stack(dist_matrices)\n",
    "        dist_matrices_summed = torch.mean(dist_matrices_stacked, 0)\n",
    "        # seq_ret = seqSLAM_from_distMatGPU_multi_precomputed(dist_matrices_summed, precomputed_convWeight)\n",
    "        # dist_matrix_seqslam = torch.nn.functional.conv2d(dist_matrices_summed, precomputed_convWeight).squeeze()\n",
    "        # match_indices = seq_ret.indices.to('cpu').detach().numpy()\n",
    "        # match_scores = seq_ret.values.to('cpu').detach().numpy()\n",
    "        # # print(f'combined P@100R: {getPAt100R(match_indices, maxLocRad)[-1]:.2f}')\n",
    "\n",
    "        # prvals = getPRCurveWrapperFromScores(match_indices, match_scores, gt_tolerance)\n",
    "\n",
    "        # match_scores_revised = np.empty(match_scores.shape, dtype=np.float32)\n",
    "        # for query in range(len(dist_matrix_seqslam)):\n",
    "        #     refs_sorted = dist_matrix_seqslam[query].argsort()\n",
    "        #     best_match = refs_sorted[0]\n",
    "        #     second_best_match = refs_sorted[torch.abs(refs_sorted - best_match) >= 3][0]\n",
    "        #     match_scores_revised[query] = dist_matrix_seqslam[query][best_match] / dist_matrix_seqslam[query][second_best_match]\n",
    "\n",
    "        # prvals_revised = getPRCurveWrapperFromScores(match_indices, match_scores_revised, gt_tolerance)\n",
    "        # # tqdm.write(f'combined R@99P: {getRAtXPFromPRVals(prvals_revised, 0.99):.2f}')\n",
    "\n",
    "        # recall_dict[num_target_pixels].append(getRAtXPFromPRVals(prvals_revised, 0.99))\n",
    "        # used_pixels_dict[num_target_pixels].append(target_pixels)\n",
    "\n",
    "    mean_recall = np.mean(recall_dict[num_target_pixels])\n",
    "    median_recall = np.median(recall_dict[num_target_pixels])\n",
    "    # tqdm.write(f'mean R@99P: {mean_recall:.2f}; median R@99P: {median_recall:.2f}; worst R@99P: {np.array(recall_dict[num_target_pixels]).min():.2f}; best R@99P: {np.array(recall_dict[num_target_pixels]).max():.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_pix = 134\n",
    "y_pix = 20\n",
    "\n",
    "# x_pix = 120\n",
    "# y_pix = 259\n",
    "\n",
    "ref = event_frames_total_thresh[0][:,x_pix,y_pix]\n",
    "# print(event_frames_total_cropped[0].shape)\n",
    "# print(ref.shape)\n",
    "qry = event_frames_total_thresh[1][:,x_pix,y_pix]\n",
    "\n",
    "filter_size = 20\n",
    "\n",
    "filter_ind = 0\n",
    "filter = qry[filter_ind:filter_ind+filter_size]\n",
    "print(filter.shape)\n",
    "corr = np.correlate(ref, filter)\n",
    "max_corr = np.max(corr)\n",
    "max_corr_ind = np.where(corr==max_corr)[0][0]\n",
    "print(\"max correlation index: \" + str(max_corr_ind))\n",
    "print(\"truth correlation index: \" + str(filter_ind))\n",
    "\n",
    "i = max_corr_ind\n",
    "print(filter)\n",
    "print(ref[i:i+filter_size])\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Reference - x_pix=\" + str(x_pix) + \" y_pix=\" + str(y_pix))\n",
    "plt.plot(np.arange(len(ref)), ref)\n",
    "plt.xlabel(\"Time\")\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Query - x_pix=\" + str(x_pix) + \" y_pix=\" + str(y_pix))\n",
    "plt.plot(np.arange(len(qry)), qry)\n",
    "plt.xlabel(\"Time\")\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Matched comparison\")\n",
    "plt.plot(np.arange(filter_size), filter)\n",
    "plt.plot(np.arange(filter_size), ref[i:i+filter_size])\n",
    "plt.legend([\"Query Filter\", \"Matched Correlation\"])\n",
    "plt.xlabel(\"Time\")\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Truth comparison\")\n",
    "plt.plot(np.arange(filter_size), filter)\n",
    "plt.plot(np.arange(filter_size), ref[filter_ind:filter_ind+filter_size])\n",
    "plt.legend([\"Reference Filter\", \"Truth Correlation\"])\n",
    "plt.xlabel(\"Time\")\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Correlation\")\n",
    "plt.plot(np.arange(len(corr)), corr)\n",
    "plt.plot(max_corr_ind, max_corr, 'r*')\n",
    "plt.xlabel(\"Time\")\n",
    "\n",
    "dmat_corr = np.zeros((len(ref)-filter_size+1,len(ref)-filter_size+1))\n",
    "print(dmat_corr.shape)\n",
    "print(ref.shape)\n",
    "for filter_ind in np.arange(len(ref)-filter_size+1):\n",
    "    filter = qry[filter_ind:filter_ind+filter_size]\n",
    "    corr = np.correlate(ref, filter)\n",
    "\n",
    "    corr_diff = np.zeros(corr.shape)\n",
    "    for idx in np.arange(len(corr_diff)):\n",
    "        corr_diff[idx] = np.sum(np.abs(ref[idx:idx+filter_size] - filter))\n",
    "    corr_norm = corr / np.max(corr)\n",
    "    corr_diff_norm = corr_diff / np.max(corr_diff)\n",
    "    dmat_corr[:,filter_ind] = corr\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(dmat_corr, robust=True, square=True, cbar=True)\n",
    "_ = plt.title('Correlation Distance matrix event camera')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "212629754625c63a4de2d2e644bbc952e1b2f1d39b51725c48e7d3300fb36356"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('EBS_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
